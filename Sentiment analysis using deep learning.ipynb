{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4eb15ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\bhagyashree\\anaconda3\\lib\\site-packages (24.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip\n",
    "!pip install -q -U watermark\n",
    "!pip install -q spacy\n",
    "!pip install -q tensorflow\n",
    "%env TF_CPP_MIN_LOG_LEVEL=3\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3669f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5241601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import math\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, CallbackList, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016617f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Bhagyashree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Bhagyashree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baceefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.a Loading Training Data\n",
    "training_data = pd.read_csv('training_data.txt', header=None, delimiter=';')\n",
    "\n",
    "# 2.b Loading Test Data\n",
    "test_data = pd.read_csv('test_data.txt', header=None, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e5c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Adjusting Column Names\n",
    "training_data = training_data.rename(columns={0: 'text', 1: 'sentiment'})\n",
    "test_data = test_data.rename(columns={0: 'text', 1: 'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671ba608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b6475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11be166e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am feeling completely overwhelmed i have two...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have the feeling she was amused and delighted</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was able to help chai lifeline with your sup...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i already feel like i fucked up though because...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i still love my so and wish the best for him i...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  i am feeling completely overwhelmed i have two...      fear\n",
       "1    i have the feeling she was amused and delighted       joy\n",
       "2  i was able to help chai lifeline with your sup...       joy\n",
       "3  i already feel like i fucked up though because...     anger\n",
       "4  i still love my so and wish the best for him i...   sadness"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45529ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Sentiments in Training Data\n",
    "training_data['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb7166",
   "metadata": {},
   "source": [
    "## There is a Python function that applies preprocessing using SpaCy, taking the text data as input. This data is passed through the dictionary. Why? For example, if I want to change the verb form of a word, I need the dictionary to handle this transformation.\n",
    "\n",
    "## This is exactly what we do here — passing the text through the dictionary. Then, I will extract the lemma. What is the lemma? It's essentially the root form of a word. The nlp object processes the text and breaks it down into tokens. In other words, it converts the text into smaller components (tokens).\n",
    "\n",
    "## After this, based on the dictionary, I extract the lemma for each token, which is its root form. I then convert it to lowercase (lower), and apply strip to clean up any unnecessary spaces.\n",
    "\n",
    "## This entire process is done inside a list comprehension, which acts as a loop in Python. For each token in my list of tokens (referred to as doc), I check if the token is valid. If so, I extract its lemma, convert it to lowercase, and apply stripto remove stop words and other unnecessary characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d24bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc5eb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3900beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Definition of the 'preprocess_text' Function, Which Takes a Text as a Parameter\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # 10.a Process the text using the SpaCy model\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # 10.b Create a list of lemmatized tokens, converted to lowercase, stripped of whitespace,\n",
    "    # excluding stopwords\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop]\n",
    "\n",
    "    # 10.c Return the processed tokens as a single string, joined with spaces\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ef4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['processed_text'] = training_data['text'].apply(preprocess_text)\n",
    "test_data['processed_text'] = test_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449ed89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am feeling completely overwhelmed i have two...</td>\n",
       "      <td>fear</td>\n",
       "      <td>feel completely overwhelmed strategy help feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have the feeling she was amused and delighted</td>\n",
       "      <td>joy</td>\n",
       "      <td>feeling amuse delight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was able to help chai lifeline with your sup...</td>\n",
       "      <td>joy</td>\n",
       "      <td>able help chai lifeline support encouragement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i already feel like i fucked up though because...</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel like fuck not usually eat morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i still love my so and wish the best for him i...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>love wish good long tolerate effect bm life fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  i am feeling completely overwhelmed i have two...      fear   \n",
       "1    i have the feeling she was amused and delighted       joy   \n",
       "2  i was able to help chai lifeline with your sup...       joy   \n",
       "3  i already feel like i fucked up though because...     anger   \n",
       "4  i still love my so and wish the best for him i...   sadness   \n",
       "\n",
       "                                      processed_text  \n",
       "0  feel completely overwhelmed strategy help feel...  \n",
       "1                              feeling amuse delight  \n",
       "2  able help chai lifeline support encouragement ...  \n",
       "3             feel like fuck not usually eat morning  \n",
       "4  love wish good long tolerate effect bm life fa...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fefc94",
   "metadata": {},
   "source": [
    "## Why are we simplified using lemmatization here is the reason its when the data gets overwhelmed \n",
    "## Simplification Steps:\n",
    "## 1:Lemmatization: Consider the first line, \"Feeling completely overwhelmed.\" As humans, we know that \"feeling\" is the gerund form of the verb feel. However, the computer cannot distinguish between gerund and verb forms. Instead of using \"feeling\", we use just the root form: \"feel\". This eliminates the need for word forms and focuses only on their roots.\n",
    "## 2:Removing Stopwords: Words like pronouns, adverbs, and common connectors (e.g., \"and,\" \"but,\" \"the\") are often unnecessary for analysis. These words are stopwords — commonly occurring words with little contextual value in most cases.\n",
    "## 3:Reducing Redundancy: Removing verbs' full forms and keeping just their roots reduces unnecessary repetition, simplifies text data, and avoids creating excessively large matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e7222af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Create the Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77570c",
   "metadata": {},
   "source": [
    "## Let's build the first version of our model. The first step is vectorization.\n",
    "\n",
    "## Since the data is in text format, and we cannot perform mathematical operations on text, we need to convert it into a numerical representation.\n",
    "\n",
    "## There are numerous strategies for this, and one of them is TF-IDF (Term Frequency-Inverse Document Frequency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5949600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 17. Check Type of Training Data TF-IDF Matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mtype\u001b[39m(train_tfidf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d785ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

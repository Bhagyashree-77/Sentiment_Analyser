{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c94c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "from transformers import BertForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef673cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read and split successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('imdb_labeled_harry_reviews.csv')\n",
    "\n",
    "# Using 'Review' and 'Sentiment' columns for training\n",
    "X = df['Cleaned Review'].values\n",
    "y = df['Sentiment'].values\n",
    "\n",
    "# Split data into training and testing data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Data read and split successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59f55889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9453, 5)\n",
      "                                              review sentiment  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive   \n",
      "1  A wonderful little production. <br /><br />The...  positive   \n",
      "2  I thought this was a wonderful way to spend ti...  positive   \n",
      "3  Basically there's a family where a little boy ...  negative   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
      "\n",
      "                                      Cleaned Review  Sentiment  \\\n",
      "0  one reviewers mentioned watching 1 oz episode ...          1   \n",
      "1  wonderful little production br br filming tech...          1   \n",
      "2  thought wonderful way spend time hot summer we...          1   \n",
      "3  basically theres family little boy jake thinks...          1   \n",
      "4  petter matteis love time money visually stunni...          1   \n",
      "\n",
      "  Sentiment Label  \n",
      "0         neutral  \n",
      "1         neutral  \n",
      "2         neutral  \n",
      "3         neutral  \n",
      "4         neutral  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)  # Should print (rows, columns)\n",
    "print(df.head())  # Check first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08d1733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b63ec86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tokenized and encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Tokenizer and Encode Data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenisasi dan encoding data\n",
    "def encode_data(texts, labels, tokenizer, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)\n",
    "\n",
    "# Encode data\n",
    "train_inputs, train_masks, train_labels = encode_data(X_train, y_train, tokenizer)\n",
    "val_inputs, val_masks, val_labels = encode_data(X_val, y_val, tokenizer)\n",
    "\n",
    "print(\"Data tokenized and encoded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0fbb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader created successfully.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "\n",
    "# Create a DataLoader for training and validation\n",
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "print(\"DataLoader created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4a968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "# Initialize BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=3, # Number of classes (negative, neutral, positive)\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Definisikan optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model and optimizer initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1cbc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training preparation done successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime  # Also required for format_time function\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Determine the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# Total training steps\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create a scheduler to adjust the learning rate during training\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Accuracy function\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Function to format time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "print(\"Training preparation done successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54683d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Training...\n",
      " Batch 40 of 473. Elapsed: 0:08:20.\n",
      " Batch 80 of 473. Elapsed: 0:16:09.\n",
      " Batch 120 of 473. Elapsed: 0:24:17.\n",
      " Batch 160 of 473. Elapsed: 0:32:12.\n",
      " Batch 200 of 473. Elapsed: 0:40:12.\n",
      " Batch 240 of 473. Elapsed: 0:48:14.\n",
      " Batch 280 of 473. Elapsed: 0:53:53.\n",
      " Batch 320 of 473. Elapsed: 0:58:22.\n",
      " Batch 360 of 473. Elapsed: 1:02:51.\n",
      " Batch 400 of 473. Elapsed: 1:07:20.\n",
      " Batch 440 of 473. Elapsed: 1:11:52.\n",
      " Average training loss: 0.12\n",
      " Training epoch took: 1:15:32\n",
      "Running Validation...\n",
      " Accuracy: 0.96\n",
      " Validation Loss: 0.15\n",
      " Validation took: 0:03:31\n",
      "Epoch 2/3\n",
      "Training...\n",
      " Batch 40 of 473. Elapsed: 0:04:31.\n",
      " Batch 80 of 473. Elapsed: 0:09:03.\n",
      " Batch 120 of 473. Elapsed: 0:13:32.\n",
      " Batch 160 of 473. Elapsed: 0:18:03.\n",
      " Batch 200 of 473. Elapsed: 0:22:34.\n",
      " Batch 240 of 473. Elapsed: 0:27:00.\n",
      " Batch 280 of 473. Elapsed: 0:31:27.\n",
      " Batch 320 of 473. Elapsed: 0:35:59.\n",
      " Batch 360 of 473. Elapsed: 0:40:31.\n",
      " Batch 400 of 473. Elapsed: 0:45:03.\n",
      " Batch 440 of 473. Elapsed: 0:49:32.\n",
      " Average training loss: 0.08\n",
      " Training epoch took: 0:53:15\n",
      "Running Validation...\n",
      " Accuracy: 0.96\n",
      " Validation Loss: 0.10\n",
      " Validation took: 0:03:32\n",
      "Epoch 3/3\n",
      "Training...\n",
      " Batch 40 of 473. Elapsed: 0:04:28.\n",
      " Batch 80 of 473. Elapsed: 0:08:58.\n",
      " Batch 120 of 473. Elapsed: 0:13:28.\n",
      " Batch 160 of 473. Elapsed: 0:17:54.\n",
      " Batch 200 of 473. Elapsed: 0:22:19.\n",
      " Batch 240 of 473. Elapsed: 0:26:44.\n",
      " Batch 280 of 473. Elapsed: 0:31:12.\n",
      " Batch 320 of 473. Elapsed: 0:35:40.\n",
      " Batch 360 of 473. Elapsed: 0:40:03.\n",
      " Batch 400 of 473. Elapsed: 0:44:30.\n",
      " Batch 440 of 473. Elapsed: 0:48:54.\n",
      " Average training loss: 0.06\n",
      " Training epoch took: 0:52:33\n",
      "Running Validation...\n",
      " Accuracy: 0.96\n",
      " Validation Loss: 0.12\n",
      " Validation took: 0:03:31\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(f'Epoch {epoch_i + 1}/{epochs}')\n",
    "    print('Training...')\n",
    "\n",
    "    # Start Timer\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Set to training model\n",
    "    model.train()\n",
    "\n",
    "    # Total loss during training\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(f' Batch {step} of {len(train_dataloader)}. Elapsed: {elapsed}.')\n",
    "\n",
    "        # Take the batch and move it to the device\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Reset the gradien\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Accumulated total loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Backward pass to calculate gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameter dan learning rate\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Average loss during training\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(f' Average training loss: {avg_train_loss:.2f}')\n",
    "    print(f' Training epoch took: {training_time}')\n",
    "\n",
    "    # Validation on the validation set\n",
    "    print('Running Validation...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(f' Accuracy: {avg_val_accuracy:.2f}')\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(f' Validation Loss: {avg_val_loss:.2f}')\n",
    "    print(f' Validation took: {validation_time}')\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dba78e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model_save/\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "output_dir = './model/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f'Model saved to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e841d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.56      0.45        48\n",
      "     neutral       0.98      0.99      0.99      1817\n",
      "    positive       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.96      1891\n",
      "   macro avg       0.45      0.52      0.48      1891\n",
      "weighted avg       0.96      0.96      0.96      1891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\BHAGYASHREE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "# Assuming model, device, and val_dataloader are already defined and initialized\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "        true_labels.extend(label_ids.flatten())\n",
    "\n",
    "# Map the numerical predictions and true labels back to sentiment labels\n",
    "sentiment_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "predictions_mapped = [sentiment_mapping[pred] for pred in predictions]\n",
    "true_labels_mapped = [sentiment_mapping[true] for true in true_labels]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels_mapped, predictions_mapped, target_names=['negative', 'neutral', 'positive'], labels=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cfcac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
